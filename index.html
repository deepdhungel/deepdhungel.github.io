<!DOCTYPE html>
<html>
  <head>
    <title>Curriculum Vitae</title>
    <style>
     /* Add some styling for the CV */
      body {
        font-family: Arial, Helvetica, sans-serif;
        margin: 0;
        padding: 0;
      }
      .header {
        background-color: hsl(150, 60%, 95%); /* Faded Minty Color */
        padding: 20px;
        text-align: center;
      }
      .header h1 {
        margin: 0;
      }
      .left-col {
        float: left;
        width: 25%;
        padding: 20px;
        background-color: hsl(150, 60%, 95%); /* Faded Minty Color */
      }
      .right-col {
        float: right;
        width: 75%;
        padding: 20px;
      }
      .clear {
        clear: both;
      }
           .section-header {
        font-weight: bold;
        margin-top: 20px;
        text-decoration: underline;
      }

      .photo {
        float: right;
        width: 25%;
        padding: 20px;
      }
      .photo img {
        width: 100%;
        height: auto;
      }
	    h1 {
    color: #0078D4; /* Microsoft blue color */
}
	   
    </style>
  </head>
  <body>
    <div class="header">
      <h1>Curriculum Vitae</h1>
    </div>
    <div class="left-col">
      <p><strong>Name:</strong> Deep Kiran Dhungel</p>
      <p><strong>Telephone:</strong> +49  15 73 32 81 22 0 </p>
      <p><strong>Address:</strong> Rabenweg 21, 14612 Falkensee</p>
      <p><strong>Github:</strong> <a href="https://github.com/deepdhungel">https://github.com/deepdhungel</a></p>
      <p><strong>Email:</strong> deep.dhungel1@gmail.com</p>
      <p><strong>Acclaim:</strong> <a href="https://www.youracclaim.com/users/deepdhungel">https://www.youracclaim.com/users/deepdhungel</a></p>
    </div>
  <div class="photo" style="width:250px">
      <img src="prfpic.png" alt="Profile Picture">
  </div>
 <div class="right-col">
      <h1 align="left">Key Skills and Competencies</h1>
      <ul>
        <li>Extensive knowledge in database design</li>
        <li>ETL design, implementation and maintenance in production</li>
		  <li align="left"> Extensive knowledge in database design, ETL design, implementation and maintenance in production.
</li> 
<li align="left"> Expertise in RDBMS such as PostgreSQL, MSSQL and MySQL.</li> 
<li align="left"> Familiarity of ETL tools such as Talend, Azure Data Factory and Apache Airflow.
</li> 
<li align="left"> Proficiency with Python and related libraries such as Pandas, Numpy, Scipy.
</li> 
<li align="left"> Competence in R and its libraries such as dplyr, dbplyr, lubridate, stringr, tidyr.
</li> 
<li align="left"> Acquaintance with visualization and reporting with Tableau, PowerBI including complex calculated fields.</li> 
<li align="left"> Command in AWS Cloud, Oracle Cloud, Azure Cloud and their arrays of tools and best practices.</li> 
<li align="left"> First experiences with Jenkins, Kubernetes and containerization with Docker.
</li> 
<li align="left"> Extensive knowledge in Unit-testing and Software Engineering best practices.</li> 
      </ul>
		<br>
<h1 align="left">Work Experience</h1>
<h2 align="left">Senior Data Exchange Manager Data Engineering</h2>
<h2 align="left">GVL - Gesellschaft zur Verwertung von Leistungsschutzrechten mbH </h2>
<p1 align="left">(May 2021 – Today)</p1>
<br><br>
<li align="left"> Manage projects for the Digital Data Exchange (DDEX RDR 1.4) standard Extract Transform and Load (ETL) pipelines as well as be the technical communication partner for the B2B Clients such as Universal Music Group, Sony Music Entertainment, Warner Music Group, Absolute Music Group.</li> 
<li align="left"> Manage projects for the upgrade of the legacy Digital Data Exchange 1.3.1 (DDEX MLC 1.3.1) standard ingestion and processing pipelines to the Digital Data Exchange 1.4 (DDEX RDR 1.4) standard ingestion and processing pipelines in Test, QA, and Production and manage onboarding of existing and new Partners to DDEX 1.4. </li> 
<li align="left"> Manage projects for the integration of music product and usage data, video product and usage data, video clip product and usage data, in private and public radio as well as tv stations in Germany to the business data warehouse.</li> 
<li align="left"> Collect technical Data Engineering requirements and find touchpoints with B2B partners (Major Record Labels) and find optimal solutions in ETL routes. </li> 
<li align="left"> Control the quality of the incoming data from the business partners to meet the Datawarehouse requirements. Reclaim data from the Partners if necessary. </li> 
<li align="left"> Find solutions to constantly improve existing data structures and data pipelines. </li> 
<li align="left"> Manage projects for the migration of legacy Data Lake in MongoDB to the Apache Drill. Analyse existing and new data in Datawarehouse and boost Data Science Projects. </li> 
<br>
		<li2 align="left"> Environment: 

PostgreSQL, MongoDB, Mongocharts, Swagger UI, Talend Openstudio, Tableau, Grafana, Python, Pandas, Anaconda, Kibana, Java Microservices, Snowflake, Apache Drill, RabbitMQ</li2>
<br>
<br>
<h2 align="left">Data Engineer</h2>
<h2 align="left">FitX Digital GmbH  </h2>
<p1 align="left">(October 2020 – February 2021)</p1>
<br><br>
<li align="left"> Architectured and designed, Fact and Dimension tables of Star Schema for Data Warehousing.</li> 
<li align="left"> Designed and implemented, ETL (Extract, Transform and Load) pipelines for the integration of data from the Data Lake to the Data Warehouse.</li> 
<li align="left"> Delivered Robust Data for the visualization.</li> 
<li align="left"> Managed Version Control for Database and Schema migration at different Instances (Development, QA and Production). </li> 
<li align="left"> Managed Release Pipelines at Development, QA and Production.</li> 
<li align="left"> Find solutions to constantly improve existing data structures and data pipelines. </li> 
<li align="left"> Managed Azure Data Factory component and component codes at repository. </li> 
		<br>
		<li2 align="left"> Environment: 

Azure Data Factory, Power BI, Active Directory, Redgate Flyway, Azure Repos, Git, MySQL, AWS S3</li2>
<br>
     <br>

<h2 align="left">Data Engineer</h2>
<h2 align="left">YAS.life</h2>
<p1 align="left">(April 2019 – September 2020)</p1>
<br><br>
<li align="left"> Designed and implemented complex ETL pipelines. Architectured DAGs (Directed Acyclic Graphs) and Task-Dependencies.</li> 
<li align="left"> Integrated data from different channels like product, marketing, and from production backend database of Live App to the staging analytics RDBMS into Datawarehouse.</li> 
<li align="left"> Optimized the performance of business-critical queries and handled related issues.</li> 
<li align="left"> Designed, implemented and maintained a platform that can provide ad-hoc access to large data sets. </li> 
<li align="left"> Performed statistical analyses of Health-Based data ( Descriptive Statistics, Regressions Model Analysis, Significance Testings, Standard Deviation, and Sample Size Determination, Hypothesis Testing).</li> 
<li align="left"> Prepared visualizations and reporting for B2B and B2C processes. </li> 
<li align="left"> Managed instances of Amazon Web Services. </li> 
		<li align="left"> Performed continuous integration and deployment.</li> 
<li align="left">Shared knowledge, organized workshops and trainings with colleagues to help company become more data-driven. </li> 
		<br>
		<li2 align="left"> Environment: 

PostgreSQL, Python, Apache Airflow, R / R Openstudio, Tableau, AWS EC2, AWS RDS, AWS S3, Jenkins, Kubernetes, Git</li2>
<br>
      <br>

<h2 align="left">Data Engineer</h2>
<h2 align="left">kloeckner.i GmbH </h2>
<p1 align="left">(October 2017 – March 2019)</p1>
<br><br>
<li align="left"> Automated numerous processes in Business Intelligence: dynamic pricing, dynamic customer segmentation, dynamic steel sales validation.</li> 
<li align="left"> Automated and integrated data from different sources in a business data warehouse for different reports and visualizations.</li> 
<li align="left"> Design and implementation of a monitoring tool for ETL jobs. </li> 
<li align="left"> Designed Extract Transform and Load (ETL) pipelines amd data models and custom Java components therefor.</li> 
<li align="left">  Cross-validated MySQL data with SAP BW, e.g. sales, billing and customer data.</li> 
<li align="left"> Administration and troubleshooting for database management systems, e.g. MySQL.</li> 
<li align="left"> Developed the Zendesk integration pipeline from scratch. </li> 
		
		<br>
		<li2 align="left"> Environment: 

Talend Openstudio, Tableau, MySQL, SAP BW, Zendesk, Automated Batchprocesses</li2>
<br>
		<br>
<h2 align="left">Database Developer </h2>
<h2 align="left">Charité, Berlin</h2>
<p1 align="left">(March 2017 - July 2017)</p1>
<br>
<br>
<li align="left"> Data pipeline development for drugs prescribed to Charité patients in Python and libraries (Pandas, Numpy, Scipy) for different targeted analyses and workflows, e.g. patient data segmentation. Please check my Github profile for further information.</li> 
<li align="left">  Design, modeling, normalization of different table structures in MySQL for Data Warehousing. Administration of the MySQL installation.</li> 
<li align="left"> Data cleaning and preparation for further analyses.</li> 
<li align="left"> Data mining and ad-hoc statistical analyses of patient and drug data, including visualization and graphical analysis.</li> 
<li align="left"> Performed different tests for non-normal patient data, to predict the stochastic equivalence as well as significant differences, null and alternative hypotheses tests.
</li>
		<br>
		<li2 align="left"> Environment: 

Python, MySQL, PostgreSQL</li2>
<br>
<br>
<h1 align="left">Academic Qualifications</h1>
	 <br>
<h2 align="left">Bioinformatics, Freie Universität Berlin</h2>
<p2 align="left">Thesis: Analysis of the Repurposing of Previously Withdrawn Drugs.</p2><br>
<p1 align="left">(Graduation Year 2017)</p1>
<br>
		
		<h2 lign="left">Studienkolleg, Martin Luther Universität Halle</h2>
<p1 align="left">(Graduation Year 2009)</p1>
		<br>
		<h2 align="left">Higher Secondary Education, National College Kathmandu</h2>
<p1 align="left">(Graduation Year 2005)</p1>
<br>	 
<br>
<br>
<h1 align="left">Training and Certifications</h1>
<h2 align="left">Oracle Autonomous Database Cloud 2019 Certified Specialist</h2>
<p2 align="left">Institution: Oracle</p2><br>
<p1 align="left">Issued On: April 2020</p1><br>
<p1 align="left">Valid Till: April 2021</p1><br>
<p1 align="left">Certification ID: 274384621OADB19-F</p1><br>
<p1 align="left">Validation Link: <a href="#">https://www.youracclaim.com/badges/475a047f-f9bf-42ab-b2eb-2d756e6153ed/linked_in_profile</a></p1><br>
<br>
<h2 align="left">Oracle Cloud Infrastructure 2019 Certified Architect Associate</h2>
<p2 align="left">Institution: Oracle</p2><br>
<p1 align="left">Issued On: April 2020</p1><br>
<p1 align="left">Valid Till: April 2021</p1><br>
<p1 align="left">Certification ID: 274540788OCSIAAS2019-F</p1><br>
<p1 align="left">Validation Link: <a href="#">https://www.youracclaim.com/badges/b270d17c-6ecc-4127-b021-9146166b05ca/linked_in_profile</a></p1><br>
<br>
<h2 align="left">Oracle Cloud Infrastructure Foundations 2020 Associate</h2>
<p2 align="left">Institution: Oracle</p2><br>
<p1 align="left">Issued On: April 2020</p1><br>
<p1 align="left">Valid Till: April 2021</p1><br>
<p1 align="left">Certification ID: 274384621OCIBF2020-F</p1><br>
<p1 align="left">Validation Link: <a href="#">https://www.youracclaim.com/badges/3874642c-1119-46df-ae3a-423220ed3ff0/linked_in_profile</a></p1><br>
<br>
<h2 align="left">AWS Certified Developer - Associate</h2>
<p2 align="left">Institution: Amazon Web Services (AWS)</p2><br>
<p1 align="left">Issued On: April 2020</p1><br>
<p1 align="left">Valid Till: April 2023</p1><br>
<p1 align="left">Certification ID: E2SJSFL2M1BQQ5K3</p1><br>
<p1 align="left">Validation Link: <a href="#">https://www.certmetrics.com/amazon/public/badge.aspx?i=2&t=c&d=2020-04-14&ci=AWS01290256</a></p1><br>
<br>
<h2 align="left">AWS Certified Cloud Practitioner</h2>
<p2 align="left">Institution: Amazon Web Services (AWS)</p2><br>
<p1 align="left">Issued On: March 2020</p1><br>
<p1 align="left">Valid Till: March 2023</p1><br>
<p1 align="left">Certification ID: HQB0FCNKGM1Q11CP</p1><br>
<p1 align="left">Validation Link: <a href="#">https://www.certmetrics.com/amazon/public/badge.aspx?i=9&t=c&d=2020-03-30&ci=AWS01290256</a></p1><br>
<br>
<h2 align="left">Machine Learning</h2>
<p2 align="left">Institution: Stanford Online</p2><br>
<p1 align="left">Issued On: February 2020</p1><br>
<p1 align="left">Valid Till: Non-Expiry</p1><br>
<p1 align="left">Certification ID: NUJCKJ9AG9LB</p1><br>
<p1 align="left">Validation Link: <a href="#">https://www.coursera.org/account/accomplishments/verify/NUJCKJ9AG9LB</a></p1>
</ul>
    
