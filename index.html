
<!DOCTYPE html>
<html>
  <head>
    <title>Curriculum Vitae</title>
	<link href="
https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.min.css
" rel="stylesheet">
	<style>
     /* Add some styling for the CV */
      body {
        font-family: Futura PT;
        margin: 0;
        padding: 0;
      }
      .header {
        background-color: hsl(210.46deg 53.64% 42.54%); /* Dark blue Color */
        padding: 15px;
        text-align: center;
      }
      .header h1 {
        margin: 0;
      }
      .left-col {
        float: left;
        width: 100%;
		text-align:center;
        padding: 15px;
        background-color: hsl(210.46deg 74.62% 90.69%); /* Faded blue Color */
      }
      .right-col {
        float: right;
        width: 75%;
        padding: 15px;
      }
      .clear {
        clear: both;
      }
           .section-header {
        font-weight: bold;
        margin-top: 15px;
        text-decoration: underline;
      }

      .photo {
        float: right;
        width: 25%;
        padding: 15px;
      }
      .photo img {
        width: 100%;
        height: auto;
      }
	    h1#name {
    
}
a{
color: black;
}
	.category-name {
	 color: hsl(210.46deg 69.96% 39.38%);
	}
	   
    </style>
  </head>
  <body>
  
 
    <div class="header">
      <h1 id="name">Deep Kiran Dhungel</h1>
    </div>
    <div class="left-col">
      <span> <i class="bi bi-telephone-fill"></i> + 1 (201) 673-2236  </span> &nbsp;&nbsp; 
      <span><i class="bi bi-github"></i> <a href="https://github.com/deepdhungel">https://github.com/deepdhungel</a></span>&nbsp;&nbsp;
      <span> <i class="bi bi-envelope-fill"></i> deep.dhungel1@gmail.com</span>&nbsp;&nbsp;
	  <span> <i class="bi bi-pin-map-fill"></i>  Astoria, NY  </span>
      <br><br><span><i class="bi bi-linkedin"></i> <a href="https://www.linkedin.com/in/deep-kiran-dhungel-a5aa5b147/">https://www.linkedin.com/in/deep-kiran-dhungel-a5aa5b147/</a></span>
	      </div>
    <br><b>
<h1 align="left" class="category-name">Professional Experience</h1>
<h2 align="left">Senior Data Manager</h2>
<h2 align="left">GVL - Gesellschaft zur Verwertung von Leistungsschutzrechten mbH </h2>
<p1 align="left"> <strong>Berlin, Germany</strong><br>
<p1 align="left">(May 2021 – Present)</p1>
<br><br>
<ul>	 
   <li>Successfully manage B2B ETL pipelines in Test, QA and Production ensuring technical communication and partnership with B2B clients such as Universal Music Group, Sony Music Entertainment, Warner Music Group, and Absolute Music Group.</li>
   <li>Lead cross-functional projects to ingest music, video and video clip product data from record labels and usage data from private and public radio and TV stations in Germany to the business data warehouse. </li>
   <li>Identify and collect technical Data Engineering requirements from product team and collaborate with them to find the best possible data flow solutions. Continuously improve existing data structures and data pipelines to enhance overall efficiency.</li>
   <li>Monitor and control the quality of incoming data from business partners to meet Datawarehouse requirements. Proactively reclaim data from partners if necessary to ensure the accuracy and completeness of data. </li>
   <li>Successfully manage projects for the migration of legacy Data in MongoDB to Snowflake. Analyze existing and new data (Delta Load) in Datawarehouse and provide insights to boost Data Science Projects. </li>

		 <br>
		<li2 align="left"> <strong>Environment:</strong> 

PostgreSQL, MongoDB, Snowflake, Swagger UI, Talend Openstudio, Tableau, Grafana, Mongo Charts, Python, Gitlab, Snowflake, RabbitMQ</li2>
</ul>
	<br>
<br>
<h2 align="left">Data Engineer</h2>
<h2 align="left">FitX Digital GmbH  </h2>
<p1 align="left"> <strong>Berlin, Germany</strong><br>
<p1 align="left">(October 2020 – February 2021)</p1>
<br><br>
<ul>	
   <li> Designed and architected Fact and Dimension tables of Star Schema for Data Warehousing, resulting in streamlined and efficient data processing.</li>
   <li> Developed ETL pipelines to integrate data from the Data Lake to the Data Warehouse, resulting in optimized data flow and increased data quality.</li>
   <li> Delivered robust data for visualization, ensuring that the data was accurate, complete, and readily available for analysis and reporting.</li>
   <li> Successfully managed release pipelines at Development, QA, and Production, ensuring that changes were properly tested and deployed.</li>
   <li> Found solutions to constantly improve existing data structures and data pipelines.</li>
   <li> Effectively managed Azure Data Factory components at the repository, ensuring that the code was properly documented and version-controlled for efficient management of the platform. </li>
		
		<br>
		<li2 align="left"> <strong>Environment: </strong>

Data Factory, Power BI, Active Directory, Redgate Flyway, Azure Repos, MySQL, AWS S3</li2>
</ul>
	<br>

<h2 align="left">Data Engineer</h2>
<h2 align="left">YAS.life</h2>
<p1 align="left"> <strong>Berlin, Germany</strong><br>
<p1 align="left">(April 2019 – September 2020)</p1>
<br><br>
<ul>	 
<li> Designed and implemented complex ETL pipelines, orchestrated using directed acyclic graphs (DAGs) and task-dependencies, to streamline data processing and improve data quality.</li>
<li> Integrated data from multiple channels, including product, marketing, and production backend databases, into the staging analytics RDBMS and Data Warehouse, enabling more comprehensive analysis and reporting.</li>
<li> Optimized the performance of business-critical queries, resolving issues to ensure the efficient processing of data and timely delivery of insights</li>
<li> Designed, implemented, and maintained a platform to provide ad-hoc access to large data sets, enabling team members to access and analyze data more easily.</li>
<li> Conducted statistical analyses of health-based data, including descriptive statistics, regression model analysis, significance testing, standard deviation, and sample size determination, and hypothesis testing, providing valuable insights into trends and patterns in the data. </li>
<li> Prepared visualizations and reports for B2B and B2C processes, effectively communicating insights to stakeholders and driving data-driven decision-making. </li>
<li> Managed Amazon Web Services instances, ensuring efficient and cost-effective use of cloud resources. Implemented continuous integration and deployment processes, ensuring that changes were properly tested and deployed in a timely and efficient manner.</li>
<li>Shared knowledge, organized workshops, and provided training to colleagues, fostering a culture of data-driven decision-making and continuous improvement. </li>
	
		<br>
		<li2 align="left"> <strong>Environment: </strong>

PostgreSQL, Python, Apache Airflow, R / R Openstudio, Tableau, AWS EC2, AWS RDS, AWS S3, Jenkins, Kubernetes, Git</li2>
</ul>
	<br>
      <br>

<h2 align="left">Data Engineer</h2>
<h2 align="left">kloeckner.i GmbH </h2>
<p1 align="left"> <strong>Berlin, Germany</strong><br>
<p1 align="left">(October 2017 – March 2019)</p1>
<br><br>
<ul>	
   <li> Leveraged automation to optimize several critical processes in Business Intelligence, including dynamic pricing, customer segmentation, and steel sales validation. </li>
   <li> Designed and implemented a comprehensive business data warehouse that integrates data from multiple sources and supports various reporting and visualization requirements. </li>
   <li>Developed a monitoring tool for ETL jobs, which enabled tracking of the data flow and detection of issues. </li>
   <li> Built custom Java components and data models to support the ETL pipelines, resulting in significant efficiency gains and higher data quality.</li>
   <li>Conducted different tests for non-normal patient data to predict the stochastic equivalence as well as significant differences, null and alternative hypotheses tests. Utilized statistical software such as R or Python, as well as tools such as Excel, to analyze and visualize the data </li>
   <li>Spearheaded the development of the Zendesk integration pipeline from scratch, streamlining data flows and enhancing the overall customer experience. </li>
  
		
		<br>
		<li2 align="left"> <strong>Environment: </strong>

Talend Openstudio, Tableau, MySQL, SAP BW, Zendesk</li2>
</ul>
		<br>
<h2 align="left">Database Developer </h2>
<h2 align="left">Charité</h2>
<p1 align="left"> <strong>Berlin, Germany</strong><br>
<p1 align="left">(March 2017 - July 2017)</p1>
<br>
<br>
<ul>	
   <li>Developed ETL pipeline for drugs database prescribed to Charité patients.</li>
   <li>Designed, modeled, and normalized complex table structures for Data Warehousing, ensuring optimal performance and data integrity. Administered and optimized the MySQL and PostgreSQL queries. </li>
   <li>Developed automated data validation and quality control checks to ensure the accuracy and completeness of the data.</li>
   <li>Conducted extensive data mining and ad-hoc statistical analyses of patient and drug data, leveraging techniques such as regression and clustering. Created insightful visualizations and graphical analyses to communicate findings to stakeholders.</li>
   <li> Conducted different tests for non-normal patient data to predict the stochastic equivalence as well as significant differences, null and alternative hypotheses tests. Utilized statistical software such as R or Python, as well as tools such as Excel, to analyze and visualize the data.
</li>
	 
		<br>
		<li2 align="left"> <strong>Environment:</strong> Python, MySQL, PostgreSQL, R</li2>
</ul>
<br>
<h1 align="left" class="category-name">Training and Certifications</h1>
<p1 align="left"><strong>Oracle Autonomous Database Cloud 2019 Certified Specialist</strong></p1>
<br><p2 align="left">Institution: Oracle</p2><br>
<p1 align="left">Issued On: April 2020</p1><br>
<br>
<p1 align="left"><strong>Oracle Cloud Infrastructure 2019 Certified Architect Associate</strong></p1>
<br><p2 align="left">Institution: Oracle</p2><br>
<p1 align="left">Issued On: April 2020</p1><br>
<br>
<p1 align="left"><strong>Oracle Cloud Infrastructure Foundations 2020 Associate</strong></p1>
<br><p2 align="left">Institution: Oracle</p2><br>
<p1 align="left">Issued On: April 2020</p1><br>
<br>
<p1 align="left"><strong>AWS Certified Developer - Associate</strong></p1>
<br><p2 align="left">Institution: Amazon Web Services (AWS)</p2><br>
<p1 align="left">Issued On: April 2020</p1><br>
<br>
<p1 align="left"><strong>AWS Certified Cloud Practitioner</strong></p1>
<br><p2 align="left">Institution: Amazon Web Services (AWS)</p2><br>
<p1 align="left">Issued On: March 2020</p1><br>
<br>
<p1 align="left"><strong>Machine Learning</strong></p1>
<br><p2 align="left">Institution: Stanford Online</p2><br>
<p1 align="left">Issued On: February 2020</p1><br>
<br>
<h1 align="left" class="category-name">Academic Qualifications</h1>
<h2 align="left">Bioinformatics B.Sc., Freie Universität Berlin  </h2> 
<p2 align="left">Thesis: Analysis of the Repurposing of Previously Withdrawn Drugs.</p2><br>
<p1 align="left">(Graduation Year 2017)</p1>
</body>
